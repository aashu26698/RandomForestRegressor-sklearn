{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAB200 -- Lab 1\n",
    "\n",
    "In this lab, you will gain some experience in creating and evaluating random forests models and in manually tuning some hyper-parameters.\n",
    "See each Part below for specific instructions but overall, keep the following in mind:\n",
    " - the code for each Part of this lab should be self-contained, that is, each of **Part 1, 2,** and **3** should contain all the necessary code and not rely on code from another **Part** of the lab in order to run (excluding import statements);\n",
    " - all parts of the lab should be done using python, sklearn, pandas, numpy, and matplotlib. \n",
    "\n",
    "**Grading:** \n",
    "\n",
    "45% of the grade will come from error-free code that accomplishes all the steps outlined in the instructions above and for each part of this lab. Another 45% will come from the comments associated with that code and answers to any questions noted, where the comments explain what the code is doing and why it is important to the overall objective. Thus, comments like \"split the data\" or \"train the model\" would receive a grade of 0 as they do not indicate any understanding. For his lab, the comments should be provided within each code cell, using the `#` character. The remaining 10% of the grade will be for formatting and clarity of comments/answers, that is, the lab should be easy to read and understand.  \n",
    "\n",
    "**What to submit**\n",
    "You should submit the following:\n",
    " - a **zip** file containing:\n",
    "     - a completed version of this notebook with **all cells executed** and **all output visible**;\n",
    "     - an html/PDF version of this notebook with all cells executed and all output visible.\n",
    "\n",
    "**Independent research will most likely be required in order to complete the lab properly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries such as Pandas, Numpy, Matplotlib, Scikit learn.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Creating and evaluating a random forest model\n",
    "\n",
    "In this part of the lab, you should:\n",
    " - read in the data;\n",
    " - verify that all the data is numeric and that there are no missing values;\n",
    " - split the data into training and validation sets with a ratio of 80:20 for training:testing;\n",
    " - create a random forest model using the data with the default hyper-parameters;\n",
    " - evaluate the model on both the training and validation sets using MAE and % error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using read_csv from pandas to read the data stored in csv format.\n",
    "\n",
    "house_data = pd.read_csv('house_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bedrooms          4600 non-null   int64  \n",
      " 1   bathrooms         4600 non-null   float64\n",
      " 2   m2_living         4600 non-null   float64\n",
      " 3   floors            4600 non-null   float64\n",
      " 4   m2_above          4600 non-null   float64\n",
      " 5   m2_basement       4600 non-null   float64\n",
      " 6   m2_lot            4600 non-null   float64\n",
      " 7   view              4600 non-null   int64  \n",
      " 8   quality           4600 non-null   int64  \n",
      " 9   yr_built          4600 non-null   int64  \n",
      " 10  renovated_last_5  4600 non-null   int64  \n",
      " 11  city              4600 non-null   int64  \n",
      " 12  statezip          4600 non-null   int64  \n",
      " 13  price             4600 non-null   float64\n",
      "dtypes: float64(7), int64(7)\n",
      "memory usage: 503.2 KB\n"
     ]
    }
   ],
   "source": [
    "house_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used info() to verify that we do not have any NULL values and all data is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using X,y variables to store parameters and target respectively.\n",
    "\n",
    "# We have splitted the data into test and train with a ratio of 20:80 respectively.\n",
    "\n",
    "# We have used and fixed value of random_state hyper-parameter so that the result do not vary everytime we run the model.\n",
    "\n",
    "X=house_data.iloc[: , :-1]\n",
    "y=house_data[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=123)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RandomForestRegressor() from sklearn.ensemble to create a random forest model with the default hyper-parameters\n",
    "\n",
    "# We have used and fixed value of random_state hyper-parameter so that the result do not vary everytime we run the model.\n",
    "\n",
    "# Using fit() to fit the model on X_train and y_train.\n",
    "\n",
    "rf1 = RandomForestRegressor(random_state=123) \n",
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$52531 average error; 9.52% error\n"
     ]
    }
   ],
   "source": [
    "# We are using predict() to make prediction using the model for X_train(training data's parameter) \n",
    "# and storing the results in predictions variable.\n",
    "\n",
    "# We are calculating mean absolute error for the prediction and the actual target we have from the data and printing the result\n",
    "# as error percentage and average amount error.\n",
    "\n",
    "predictions = rf1.predict(X_train)\n",
    "e = mean_absolute_error(y_train, predictions)\n",
    "ep = e*100 / y.mean()\n",
    "print(f\"${e:.0f} average error; {ep:.2f}% error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$131978 average error; 23.91% error\n"
     ]
    }
   ],
   "source": [
    "# We are using predict() to make prediction using the model for X_test(testing data's parameter)\n",
    "# and storing the results in validation_predictions variable.\n",
    "\n",
    "# We are calculating mean absolute error for the prediction and the actual target we have from the data and printing the result\n",
    "# as error percentage and average amount error.\n",
    "\n",
    "validation_predictions = rf1.predict(X_test)\n",
    "validation_e = mean_absolute_error(y_test, validation_predictions)\n",
    "validation_ep = validation_e * 100 / y.mean() \n",
    "print(f\"${validation_e:.0f} average error; {validation_ep:.2f}% error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts training data with an accuracy of 90.48%, but when evaluated for testing data the error percent increased from 9.52% to 23.91%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Exploring the `n_estimators` hyper-parameter\n",
    "\n",
    "In this part of the lab you should: \n",
    " - use a `for` loop to create a random forest model for each value of `n_estimators` from 1 to 30;\n",
    " - evaluate each model on the validation set only using MAE;\n",
    "\n",
    "After that you should answer the following questions:\n",
    " - Which value of `n_estimators` gives the best results? \n",
    " - Explain how you decided that this value for `n_estimators` gave the best results;\n",
    " - Was the result here better than the result of Part 1? What % better or worse was it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using read_csv from pandas to read the data stored in csv format.\n",
    "\n",
    "house_data = pd.read_csv('house_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using X,y variables to store parameters and target respectively.\n",
    "\n",
    "# We have splitted the data into test and train with a ratio of 20:80 respectively.\n",
    "\n",
    "# We have used and fixed value of random_state hyperparameter so that the result do not vary everytime we run model.\n",
    "\n",
    "X=house_data.iloc[: , :-1]\n",
    "y=house_data[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get best results from 26 estimators\n"
     ]
    }
   ],
   "source": [
    "# Using RandomForestRegressor() from sklearn.ensemble to create a random forest model with the n_estimators \n",
    "# hyper-parameter value between 1 and 30.\n",
    "\n",
    "# We have created empty list testing_errors to store all testing dataset errors for n_estimators from 1 to 30.\n",
    "\n",
    "# Using fit() to fit the model on X_train and y_train.\n",
    "\n",
    "# We have used and fixed value of random_state hyper-parameter so that the result do not vary everytime we run the model.\n",
    "\n",
    "# We are using predict() to make prediction using the model for X_test(testing data's parameter)\n",
    "# and storing the results in validation_predictions variable.\n",
    "\n",
    "# We are calculating mean absolute error for the prediction and the actual target we have from the data and storing the \n",
    "# resulting percentage error in a testing_errors list.\n",
    "\n",
    "# In the end we are finding the value of n_estimators with least error percentage and \n",
    "# storing it into n_est variable for future use.\n",
    "\n",
    "testing_errors=[]\n",
    "\n",
    "for i in range(1,31):\n",
    "    rf2 = RandomForestRegressor(n_estimators=i,random_state=123) \n",
    "    rf2.fit(X_train, y_train)\n",
    "    validation_predictions = rf2.predict(X_test)\n",
    "    validation_e = mean_absolute_error(y_test, validation_predictions)\n",
    "    validation_ep = validation_e * 100 / y.mean()\n",
    "    testing_errors.append(validation_ep)\n",
    "\n",
    "n_est = testing_errors.index(min(testing_errors))\n",
    "print(f\"We get best results from {n_est} estimators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value for n_estimators is selected on the basis of the minimum error in testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$130375 average error; 23.62% error\n"
     ]
    }
   ],
   "source": [
    "# Using RandomForestRegressor() from sklearn.ensemble to create a random forest model with the n_estimators \n",
    "# hyper-parameter value as calculated before.\n",
    "\n",
    "# Using fit() to fit the model on X_train and y_train.\n",
    "\n",
    "# We have used and fixed value of random_state hyper-parameter so that the result do not vary everytime we run model.\n",
    "\n",
    "# We are using predict() to make prediction using the model for X_test(testing data's parameter)\n",
    "# and storing the results in validation_predictions variable.\n",
    "\n",
    "# We are calculating mean absolute error for the prediction and the actual target we have from the data and printing the result\n",
    "# as error percentage and average amount error.\n",
    "\n",
    "rf3=RandomForestRegressor(n_estimators=n_est,random_state=123)\n",
    "rf3.fit(X_train,y_train)\n",
    "validation_predictions = rf3.predict(X_test)\n",
    "validation_e = mean_absolute_error(y_test, validation_predictions)\n",
    "validation_ep = validation_e * 100 / y.mean() \n",
    "print(f\"${validation_e:.0f} average error; {validation_ep:.2f}% error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The results here shows that the model in Part 2 is slightly better than the one in Part 1 with default parameters.\n",
    "- There is just 0.29% less error in testing/validation prediction as compared to model in Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Exploring the `max_features` hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the lab you should: \n",
    " - use a `for` loop to create a random forest model for each value of `max_features` from 1 to the total number of features in the data;\n",
    " - for each model, use the value for `n_estimators` as determined in Part 2;\n",
    " - evaluate each model on the testing set using MAE;\n",
    " \n",
    "After that you should answer the following questions:\n",
    " - Which value of `max_features` gives the best results?\n",
    " - Explain how you decided that this value for `max_features` gave the best results;\n",
    " - Was the result here better than the result of Part 2? Why is that? What % better or worse was it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using read_csv from pandas to read the data stored in csv format.\n",
    "\n",
    "house_data = pd.read_csv('house_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using X,y variables to store parameters and target respectively.\n",
    "\n",
    "# We have splitted the data into test and train with a ratio of 20:80 respectively.\n",
    "\n",
    "# We have used and fixed value of random_state hyperparameter so that the result do not vary everytime we run the model.\n",
    "\n",
    "X=house_data.iloc[: , :-1]\n",
    "y=house_data[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get best results from 12 features.\n"
     ]
    }
   ],
   "source": [
    "# Using RandomForestRegressor() from sklearn.ensemble to create a random forest model with the n_estimators hyper-parameter as \n",
    "# calculated and stored in n_est and max_features is checked between 1 to number of columns.\n",
    "\n",
    "# We have created empty list testing_errors to store all testing dataset errors for max_features from 1 to number of features. \n",
    "\n",
    "# Using fit() to fit the model on X_train and y_train.\n",
    "\n",
    "# We have used and fixed value of random_state hyper-parameter so that the result do not vary everytime we run model.\n",
    "\n",
    "# We are calculating mean absolute error for the prediction and the actual target we have from the data and storing the \n",
    "# resulting percentage error in a testing_errors list.\n",
    "\n",
    "# In the end we are finding the value of max_features hyper-parameter with least error percentage and \n",
    "# storing it into max_features_result variable for future use.\n",
    "\n",
    "testing_errors=[]\n",
    "\n",
    "for i in range(1,len(X.columns)+1):\n",
    "    rf4 = RandomForestRegressor(n_estimators=n_est,max_features=i,random_state=123) \n",
    "    rf4.fit(X_train, y_train)\n",
    "    validation_predictions = rf4.predict(X_test)\n",
    "    validation_e = mean_absolute_error(y_test, validation_predictions)\n",
    "    validation_ep = validation_e * 100 / y.mean()\n",
    "    testing_errors.append(validation_ep)\n",
    "\n",
    "max_features_result = testing_errors.index(min(testing_errors))\n",
    "print(f\"We get best results from {max_features_result} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value for max_features is selected on the basis of the minimum error in testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$132851 average error; 24.07% error\n"
     ]
    }
   ],
   "source": [
    "# Using RandomForestRegressor() from sklearn.ensemble to create a random forest model with the n_estimators hyper-parameter as \n",
    "# calculated and stored in n_est and max_features as calculated before and stored in max_features_results.\n",
    "\n",
    "# Using fit() to fit the model on X_train and y_train.\n",
    "\n",
    "# We have used and fixed value of random_state hyperparameter so that the result do not vary everytime we run model.\n",
    "\n",
    "# We are using predict() to make prediction using the model for X_test(testing data's parameter)\n",
    "# and storing the results in validation_predictions variable.\n",
    "\n",
    "# We are calculating mean absolute error for the prediction and the actual target we have from the data and printing the result\n",
    "# as error percentage and average amount error.\n",
    "\n",
    "# We have used the value of n_estimators and max_features hyper-parameter from the varibale n_est and max_features_result\n",
    "# respectiveley and they have been calculated before.\n",
    "\n",
    "rf5=RandomForestRegressor(max_features=max_features_result,n_estimators=n_est,random_state=123)\n",
    "rf5.fit(X_train,y_train)\n",
    "validation_predictions = rf5.predict(X_test)\n",
    "validation_e = mean_absolute_error(y_test, validation_predictions)\n",
    "validation_ep = validation_e * 100 / y.mean() \n",
    "print(f\"${validation_e:.0f} average error; {validation_ep:.2f}% error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The results here shows that the model in Part 2 performes slightly better as compared to this one.\n",
    "- There is 0.45% more error in validation prediction as compared to model in part 2, the possible reason behind this is that\n",
    "  the combination of slight errors from n_estimators and max_features adds upto a slightly bigger figure than model with default hyper-parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
